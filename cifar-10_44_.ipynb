{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1609909995282,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "T6VGs7h44Zwb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 92575,
     "status": "ok",
     "timestamp": 1609910088108,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "7-xl85y4AH7u"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('drive/MyDrive/cifar_x.csv')\n",
    "df2 = pd.read_csv('drive/MyDrive/cifar_y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural nets in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1609910089349,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "By_ulAJ_5qpV"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    a = 1/(1 + np.exp(-z))\n",
    "    return a\n",
    "\n",
    "def relu(Z):\n",
    "    z = np.copy(Z)\n",
    "    np.maximum(z,0,z)\n",
    "    return z\n",
    "\n",
    "def leaky_relu(Z,slope=0.001):\n",
    "    z = np.copy(Z)\n",
    "    np.maximum(z,slope*z,z)\n",
    "    return z\n",
    "\n",
    "def derivative_leaky(a,slope=0.001):\n",
    "    da = np.int64(a>0)*1 + np.int64(a<=0)*slope\n",
    "    return da\n",
    "\n",
    "def softmax(z):\n",
    "    a = np.exp(z)/np.sum(np.exp(z),axis=0)\n",
    "    return a\n",
    "\n",
    "def derivative_relu(a):\n",
    "    da = np.int64(a>0)*1\n",
    "    return da\n",
    "\n",
    "def derivative_sig(a):\n",
    "    da = a * (1-a)\n",
    "    return da\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    # layer_dims is a list of nodes in each layer. architechture of the network\n",
    "    # we are doing he-initialization\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\"+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1]) * np.sqrt(2/layer_dims[l-1])\n",
    "        parameters[\"b\"+str(l)] = np.zeros((layer_dims[l],1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters    \n",
    "\n",
    "def organize_activations(activations,L):\n",
    "    #activations: list of strings of activations\n",
    "    #L: no. of layers (excluding input)\n",
    "    acts = {}\n",
    "    if activations is None:\n",
    "        for l in range(1,L):\n",
    "            acts[\"act\"+str(l)] = \"relu\"\n",
    "        acts[\"act\"+str(L)] = \"sigmoid\"\n",
    "    else:\n",
    "        for l in range(1,L+1):\n",
    "            acts[\"act\"+str(l)] = activations[l-1]\n",
    "    return acts\n",
    "\n",
    "def get_keep_probs(d):\n",
    "    if d is None:\n",
    "        return None\n",
    "    else :\n",
    "        d = np.array(d)\n",
    "        a = 1-d\n",
    "        return a\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1801,
     "status": "ok",
     "timestamp": 1609910089942,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "P3k3H-N-7iF4"
   },
   "outputs": [],
   "source": [
    "def find_z(A_prev,W,b):\n",
    "    # A_prev: activation from prev layer\n",
    "    # W,b: weights and bias of current layer\n",
    "    \n",
    "    z = np.dot(W,A_prev) + b\n",
    "    \n",
    "    assert(z.shape == (W.shape[0],A_prev.shape[1]))\n",
    "    cache = (A_prev,W,b)\n",
    "    \n",
    "    return z,cache #cache format returned for a layer: (A_prev,W,b)\n",
    "\n",
    "def forward_activation(A_prev,W,b,activation):\n",
    "    z,cache = find_z(A_prev,W,b)\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        a = sigmoid(z)\n",
    "    elif activation == \"relu\":\n",
    "        a = relu(z)\n",
    "    elif activation == \"softmax\":\n",
    "        a = softmax(z)\n",
    "    elif activation == \"leaky_relu\":\n",
    "        a = leaky_relu(z)\n",
    "    \n",
    "    assert (a.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (cache,a)\n",
    "    \n",
    "    return a,cache #cache format for a layer: ((A_prev,W,b),A)\n",
    "\n",
    "#feed forward network\n",
    "def forward_propagation(X,parameters,acts=None):\n",
    "    L = len(parameters)//2\n",
    "    A = X\n",
    "    caches = []\n",
    "    \n",
    "    if acts is None:\n",
    "        acts = organize_activations(acts,L)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        A,cache = forward_activation(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],activation=acts[\"act\"+str(l)])\n",
    "        caches.append(cache)\n",
    "        \n",
    "    A_L,cache = forward_activation(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],activation=acts[\"act\"+str(L)])\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A_L,caches #caches is for each layer(except input): ((A_prev,W,b),A)\n",
    "\n",
    "#forward prop with dropouts:\n",
    "def forward_activation_with_dropouts(A_prev,W,b,activation,keep_prob):\n",
    "    z,cache = find_z(A_prev,W,b)\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        a = sigmoid(z)\n",
    "    elif activation == \"relu\":\n",
    "        a = relu(z)\n",
    "    elif activation == \"softmax\":\n",
    "        a = softmax(z)\n",
    "    elif activation == \"leaky_relu\":\n",
    "        a = leaky_relu(z)\n",
    "    \n",
    "    #dropping out\n",
    "    D = np.random.rand(a.shape[0],a.shape[1])\n",
    "    D = D < keep_prob\n",
    "    a = a * D\n",
    "    a = a / keep_prob\n",
    "    \n",
    "    assert (a.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (cache,a,D)\n",
    "    \n",
    "    return a,cache #cache format for a layer: ((A_prev,W,b),A,D)\n",
    "\n",
    "def forward_propagation_with_dropouts(X,parameters,keep_probs,acts=None):\n",
    "    #keep_probs: list of keep_probs\n",
    "    L = len(parameters)//2\n",
    "    A = X\n",
    "    caches = []\n",
    "    \n",
    "    if acts is None:\n",
    "        acts = organize_activations(acts,L)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        A,cache = forward_activation_with_dropouts(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],activation=acts[\"act\"+str(l)],keep_prob=keep_probs[l-1])\n",
    "        caches.append(cache)\n",
    "        \n",
    "    A_L,cache = forward_activation_with_dropouts(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],activation=acts[\"act\"+str(L)],keep_prob=1)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A_L,caches # caches for each layer: ((A_prev,W,b),A,D)\n",
    "\n",
    "def loss(h,y):\n",
    "    #L_sum = np.sum(y*np.log(h)) + np.sum((1-y)*(np.log(1-h)))\n",
    "    #even if one prediction is way off then cost shoots up to inf. you can use any of the two eqns in this code\n",
    "    L_sum = np.sum(np.log(h[y==1])) + np.sum(np.log(1-h[y==0]))\n",
    "    m = y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L\n",
    "\n",
    "def loss_with_regularization(h,y,parameters,lambd):\n",
    "    m = y.shape[1]\n",
    "    L = len(parameters)//2\n",
    "    cross_entropy_cost = loss(h,y)\n",
    "    L2_regularization_cost = 0\n",
    "    for l in range(L):\n",
    "        L2_regularization_cost += np.sum(np.square(parameters[\"W\"+str(l+1)]))\n",
    "    L2_regularization_cost = lambd * L2_regularization_cost / (2*m)\n",
    "    cost = cross_entropy_cost + L2_regularization_cost\n",
    "    return cost\n",
    "\n",
    "def find_grads(dz,cache,lambd):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = (np.dot(dz,A_prev.T) / m) + (lambd * W)/m\n",
    "    db = np.sum(dz,axis=1,keepdims=True) / m\n",
    "    dA_prev = np.dot(W.T,dz)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linear_backwards(dA,cache,activation,lambd,keep_prop=None):\n",
    "    if keep_prop is None:\n",
    "        c,A = cache\n",
    "    else:\n",
    "        c,A,D = cache\n",
    "        dA = dA * D\n",
    "        dA = dA / keep_prop\n",
    "        A = A * keep_prop # just to find accurate derivative for my defined functions. \n",
    "        #the above line won't matter in relu/leaky but better approximation for sigmoid\n",
    "        \n",
    "    if activation == \"relu\":\n",
    "        dz = dA * derivative_relu(A)\n",
    "    \n",
    "    elif activation == \"sigmoid\":\n",
    "        dz = dA * derivative_sig(A)\n",
    "        \n",
    "    elif activation == \"leaky_relu\":\n",
    "        dz = dA * derivative_leaky(A)\n",
    "     \n",
    "    dA_prev, dW, db = find_grads(dz, c,lambd)\n",
    "    return dA_prev,dW,db\n",
    "\n",
    "def backprop(A_L,Y,caches,lambd,acts=None,keep_probs=None):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = A_L.shape[1]\n",
    "    Y = Y.reshape(A_L.shape)\n",
    "    \n",
    "    if not acts:\n",
    "        acts = organize_activations(acts,L)\n",
    "    \n",
    "    \n",
    "    cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = find_grads((A_L-Y),cache[0],lambd)\n",
    "    \n",
    "    if keep_probs is None:\n",
    "        for l in reversed(range(L-1)):\n",
    "            cache = caches[l]\n",
    "            grads[\"dA\" + str(l)], grads[\"dW\" + str(l+1)], grads[\"db\" + str(l+1)] = linear_backwards(grads[\"dA\"+str(l+1)],cache,activation=acts[\"act\"+str(l+1)],lambd=lambd)\n",
    "    \n",
    "    else:\n",
    "        for l in reversed(range(L-1)):\n",
    "            cache = caches[l]\n",
    "            grads[\"dA\" + str(l)], grads[\"dW\" + str(l+1)], grads[\"db\" + str(l+1)] = linear_backwards(grads[\"dA\"+str(l+1)],cache,activation=acts[\"act\"+str(l+1)],lambd=lambd,keep_prop=keep_probs[l])\n",
    "    \n",
    "    return grads\n",
    "\n",
    "def update_parameters(parameters,grads,learning_rate):\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "def random_mini_batches(X,Y,batch_size,shuffle):\n",
    "    m = X.shape[1]\n",
    "    batches = []\n",
    "    \n",
    "    if shuffle:\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X[:,permutation]\n",
    "        shuffled_Y = Y[:,permutation]\n",
    "    \n",
    "    else:\n",
    "        shuffled_X = X\n",
    "        shuffled_Y = Y\n",
    "    \n",
    "    for i in range(m//batch_size):\n",
    "        mini_x = shuffled_X[:,i*batch_size:(i+1)*batch_size]\n",
    "        mini_y = shuffled_Y[:,i*batch_size:(i+1)*batch_size]\n",
    "        batch = (mini_x,mini_y)\n",
    "        batches.append(batch)\n",
    "    \n",
    "    if m%batch_size !=0:\n",
    "        mini_x = shuffled_X[:,batch_size*(m//batch_size):]\n",
    "        mini_y = shuffled_Y[:,batch_size*(m//batch_size):]\n",
    "        batch = (mini_x,mini_y)\n",
    "        batches.append(batch)\n",
    "    return batches\n",
    "\n",
    "def initialize_adam(parameters):\n",
    "    L = len(parameters)//2\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\"+str(l+1)] = np.zeros_like(parameters[\"W\"+str(l+1)])\n",
    "        v[\"db\"+str(l+1)] = np.zeros_like(parameters[\"b\"+str(l+1)])\n",
    "        \n",
    "        s[\"dW\"+str(l+1)] = np.zeros_like(parameters[\"W\"+str(l+1)])\n",
    "        s[\"db\"+str(l+1)] = np.zeros_like(parameters[\"b\"+str(l+1)])\n",
    "        \n",
    "    return v,s\n",
    "\n",
    "def update_parameters_with_adam(parameters,grads,v,s,t,lr=0.01,beta1=0.9,beta2=0.999,epsilon=1e-7):\n",
    "    L = len(parameters)//2\n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * grads['db' + str(l + 1)]\n",
    "        \n",
    "        s[\"dW\" + str(l + 1)] = beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) * np.power(grads['dW' + str(l + 1)], 2)\n",
    "        s[\"db\" + str(l + 1)] = beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grads['db' + str(l + 1)], 2)\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l + 1)] = v[\"dW\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l + 1)] = v[\"db\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l + 1)] = s[\"dW\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l + 1)] = s[\"db\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        \n",
    "        parameters[\"W\"+str(l+1)] = parameters[\"W\"+str(l+1)] - lr * (v_corrected[\"dW\"+str(l+1)]/np.sqrt(s_corrected[\"dW\"+str(l+1)]+epsilon))\n",
    "        parameters[\"b\"+str(l+1)] = parameters[\"b\"+str(l+1)] - lr * (v_corrected[\"db\"+str(l+1)]/np.sqrt(s_corrected[\"db\"+str(l+1)]+epsilon))\n",
    "        \n",
    "    return parameters,v,s  \n",
    "\n",
    "def predict(X,Y,parameters):\n",
    "    Y_pred,c = forward_propagation(X,parameters)\n",
    "    prediction = np.argmax(Y_pred, axis=0)\n",
    "    labels = np.argmax(Y, axis=0)\n",
    "\n",
    "    diff=prediction-labels \n",
    "    accuracy = 1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
    "    print(accuracy*100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1609914033310,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "mbKmdFjK-7Ac"
   },
   "outputs": [],
   "source": [
    "def fit(X,Y,layer_dims,parameters=None,activations=None,validation_data=None,drop_probs=None,lr=0.01,beta1=0.9,beta2=0.999,lambd=0,epochs=3,batch_size=256,shuffle=True,optimizer=\"adam\",print_cost=0):\n",
    "    costs = []\n",
    "    m = X.shape[1]\n",
    "    t=0\n",
    "#     if not parameters:\n",
    "#         try:\n",
    "#             parameters\n",
    "#         except NameError:\n",
    "#             parameters = initialize_parameters(layer_dims)\n",
    "    if parameters is None:\n",
    "        parameters = initialize_parameters(layer_dims)\n",
    "    \n",
    "    acts = organize_activations(activations,len(layer_dims)-1)\n",
    "    \n",
    "    if optimizer==\"adam\":\n",
    "        v,s = initialize_adam(parameters)\n",
    "        \n",
    "    keep_probs = get_keep_probs(drop_probs)\n",
    "        \n",
    "    for i in range(epochs):\n",
    "        cost = 0\n",
    "        mini_batches = random_mini_batches(X,Y,batch_size,shuffle)\n",
    "        for batch in mini_batches:\n",
    "            (mini_x,mini_y) = batch\n",
    "            if keep_probs is None:\n",
    "                A_L,caches = forward_propagation(mini_x,parameters,acts)\n",
    "            else:\n",
    "                A_L,caches = forward_propagation_with_dropouts(mini_x,parameters,acts=acts,keep_probs=keep_probs)\n",
    "            cost += loss_with_regularization(A_L,mini_y,parameters=parameters,lambd=lambd) #default lambd=0. \n",
    "            grads = backprop(A_L,mini_y,caches,acts=acts,lambd=lambd,keep_probs=keep_probs)\n",
    "            #update parameters:\n",
    "            if optimizer==\"adam\":\n",
    "                t = t+1\n",
    "                parameters,v,s = update_parameters_with_adam(parameters,grads,v,s,t,lr,beta1,beta2)\n",
    "            else:\n",
    "                parameters = update_parameters(parameters,grads,lr)\n",
    "        \n",
    "        cost = cost/len(mini_batches)\n",
    "        if print_cost!=0 and i % print_cost == 0:\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "            predict(X,Y,parameters)\n",
    "            if validation_data is not None:\n",
    "              predict(validation_data[0],validation_data[1],parameters)\n",
    "        if print_cost!=0 and i % print_cost == 0:\n",
    "            costs.append(cost)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 2624,
     "status": "ok",
     "timestamp": 1609849952810,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "xgpwrXCsFAoB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing cifar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 1688,
     "status": "ok",
     "timestamp": 1609912535965,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "eGnppVGvFBIk",
    "outputId": "b52ccd8a-8c18-4eb5-b298-045f4233037e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CIFAR\n",
    "\n",
    "x = np.array(df1)\n",
    "y_ = np.array(df2)\n",
    "x = x.reshape((1024,60000))\n",
    "y_ = y_.reshape((10,60000))\n",
    "x = x/255.0 \n",
    "#separating train and test\n",
    "x_train = x[:,:-10000]\n",
    "x_test = x[:,-10000:]\n",
    "y_test = y_[:,-10000:]\n",
    "y_train = y_[:,:-10000]\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "x_train = x_train.reshape((50000,32,32))\n",
    "x_test = x_test.reshape((10000,32,32))\n",
    "# x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "# x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "\n",
    "x_train = x_train.reshape((50000,1024))\n",
    "x_train = x_train.T\n",
    "x_test = x_test.reshape((10000,1024))\n",
    "x_test = x_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15416,
     "status": "ok",
     "timestamp": 1609914248022,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "27cx6Zm-27gj",
    "outputId": "f0a43c22-1287-457d-c470-9bf1480033a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.262942\n",
      "50.38199999999999\n",
      "43.02\n"
     ]
    }
   ],
   "source": [
    "lay = [x_train.shape[0],512,10]\n",
    "try:\n",
    "  p\n",
    "except NameError:\n",
    "  p =  initialize_parameters(lay)\n",
    "a = ['relu',\"sigmoid\"]\n",
    "drops = None\n",
    "p = fit(x_train,y_train,layer_dims=lay,activations=a,parameters=p,validation_data=(x_test,y_test),drop_probs=drops,lr=0.001,epochs=1,print_cost=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2992,
     "status": "ok",
     "timestamp": 1609914278849,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "3fWPVB7P4Syu",
    "outputId": "3e18b6f7-e2a4-49dd-ba15-4b0e316fd8b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.38199999999999\n",
      "43.02\n"
     ]
    }
   ],
   "source": [
    "predict(x_train,y_train,p)\n",
    "predict(x_test,y_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1609913384410,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "B2GrUZu-6dOO"
   },
   "outputs": [],
   "source": [
    "p = initialize_parameters(lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43977,
     "status": "ok",
     "timestamp": 1609908318659,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "FzWmypRfdr_S",
    "outputId": "bd698763-33d6-4310-d184-a647be273398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (0.48.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba) (51.0.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba) (1.19.4)\n",
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.1/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n"
     ]
    }
   ],
   "source": [
    "!pip install numba\n",
    "!find / -iname 'libdevice'\n",
    "!find / -iname 'libnvvm.so'\n",
    "from numba import jit, njit, vectorize, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1609909164028,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "hvcPnjJG4MTm"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def lol(a,b):\n",
    "  return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22679,
     "status": "ok",
     "timestamp": 1609909189305,
     "user": {
      "displayName": "SB- 9",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggaealg2y2yZqJ6RpX3cZBcdBwTfdZCR-fQeicC-A=s64",
      "userId": "01448517634576686850"
     },
     "user_tz": -330
    },
    "id": "20VrIfQZACrL",
    "outputId": "c74ce70d-b8c5-4f5c-e2ec-ddff202d4e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 5.29 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit for i in range(100): a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJIuOWm-AlSo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL76Of01htLCZj7hoPcVpP",
   "collapsed_sections": [],
   "mount_file_id": "1Np_TAxu6GQGEzYzREfN-5Ot1uRuKj2vn",
   "name": "cifar-10_90%acc.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
